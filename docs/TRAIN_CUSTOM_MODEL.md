# Ø¯Ù„ÙŠÙ„ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ AI Ù…Ø®ØµØµ Ù„ÙƒØ´Ù Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª

## ğŸ“ Ø§Ù„Ø®ÙŠØ§Ø± 2: ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„ØµÙØ±

---

## ğŸ“‹ **Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©**

### Ù…Ø§ Ø³Ù†ÙØ¹Ù„Ù‡:
```
1. Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØµÙˆØ± Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª)
2. ØªØ¬Ù‡ÙŠØ² ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
3. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
4. ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù€ TFLite (Ù„Ù„Ù€ Edge AI)
5. Ø¯Ù…Ø¬ Ù…Ø¹ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
```

### Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©:
- ğŸ“Š **Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: 1-2 Ø£Ø³Ø¨ÙˆØ¹
- ğŸ‹ï¸ **Ø§Ù„ØªØ¯Ø±ÙŠØ¨**: 2-6 Ø³Ø§Ø¹Ø§Øª (Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø§Ø²)
- âš™ï¸ **Ø§Ù„ØªØ­Ø³ÙŠÙ†**: 1-3 Ø£ÙŠØ§Ù…

---

## 1ï¸âƒ£ **Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Dataset Collection)**

### Ù…Ø§ Ù†Ø­ØªØ§Ø¬Ù‡:

#### Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰:
```
ğŸ“ dataset/
â”œâ”€â”€ bleeding/          # 200+ ØµÙˆØ±Ø© Ù†Ø²ÙŠÙ
â”œâ”€â”€ bruise/            # 200+ ØµÙˆØ±Ø© ÙƒØ¯Ù…Ø§Øª
â”œâ”€â”€ burn/              # 200+ ØµÙˆØ±Ø© Ø­Ø±ÙˆÙ‚
â”œâ”€â”€ cut/               # 200+ ØµÙˆØ±Ø© Ø¬Ø±ÙˆØ­
â”œâ”€â”€ fracture/          # 200+ ØµÙˆØ±Ø© ÙƒØ³ÙˆØ±
â”œâ”€â”€ swelling/          # 200+ ØµÙˆØ±Ø© ØªÙˆØ±Ù…
â””â”€â”€ normal/            # 300+ ØµÙˆØ±Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© (Ø¨Ø¯ÙˆÙ† Ø¥ØµØ§Ø¨Ø©)
```

#### Ø§Ù„Ø£ÙØ¶Ù„:
```
âœ… 500-1000 ØµÙˆØ±Ø© Ù„ÙƒÙ„ ÙØ¦Ø©
âœ… ØªÙ†ÙˆØ¹ ÙÙŠ:
   - Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© (Ù†Ù‡Ø§Ø±ØŒ Ù„ÙŠÙ„ØŒ Ø¯Ø§Ø®Ù„ÙŠØŒ Ø®Ø§Ø±Ø¬ÙŠ)
   - Ø§Ù„Ø²ÙˆØ§ÙŠØ§ (Ù‚Ø±ÙŠØ¨ØŒ Ø¨Ø¹ÙŠØ¯ØŒ Ø¬Ø§Ù†Ø¨ÙŠ)
   - Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨Ø´Ø±Ø©
   - Ø´Ø¯Ø© Ø§Ù„Ø¥ØµØ§Ø¨Ø©
```

### ğŸ” Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:

#### 1. Datasets Ø·Ø¨ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø© (Ù…Ø¬Ø§Ù†ÙŠØ©):
```python
# Ù…Ø«Ø§Ù„: Kaggle Datasets
- Wound Detection Dataset
- Medical Image Dataset
- Skin Lesion Dataset

# Ø§Ù„ØªØ­Ù…ÙŠÙ„:
# https://www.kaggle.com/datasets
# https://github.com/topics/medical-imaging
```

#### 2. Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ©:
```python
âœ… Ø§Ù„ØªÙ‚Ø· ØµÙˆØ± ØªØ¯Ø±ÙŠØ¨ÙŠØ© (Ù…Ø¹ Ø§Ù„Ø¥Ø°Ù†!)
âœ… Ø§Ø³ØªØ®Ø¯Ù… ØµÙˆØ± simulation/makeup Ù„Ù„Ø¥ØµØ§Ø¨Ø§Øª
âœ… ØµÙˆØ± Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª (Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø­Ù‚ÙˆÙ‚)
```

#### 3. Data Augmentation:
```python
# Ù„Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª
- Rotation (ØªØ¯ÙˆÙŠØ±)
- Flip (Ù‚Ù„Ø¨)
- Brightness (Ø³Ø·ÙˆØ¹)
- Zoom (ØªÙ‚Ø±ÙŠØ¨)
- Noise (Ø¶ÙˆØ¶Ø§Ø¡)

# Ø§Ù„Ù†ØªÙŠØ¬Ø©: 200 ØµÙˆØ±Ø© â†’ 1000+ ØµÙˆØ±Ø©!
```

---

## 2ï¸âƒ£ **ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Preparation)**

### Ø³ÙƒØ±ÙŠØ¨Øª ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:

```python
# scripts/prepare_dataset.py
import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def load_dataset(data_dir):
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª"""
    images = []
    labels = []
    
    classes = ['normal', 'bleeding', 'bruise', 'burn', 'cut', 'fracture', 'swelling']
    
    for idx, class_name in enumerate(classes):
        class_dir = os.path.join(data_dir, class_name)
        
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
            img = cv2.imread(img_path)
            if img is None:
                continue
                
            # Resize to 224x224 (Ø­Ø¬Ù… Ù‚ÙŠØ§Ø³ÙŠ)
            img = cv2.resize(img, (224, 224))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            images.append(img)
            labels.append(idx)
    
    return np.array(images), np.array(labels)

# 2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
images, labels = load_dataset('dataset/')

# 80% ØªØ¯Ø±ÙŠØ¨ØŒ 20% Ø§Ø®ØªØ¨Ø§Ø±
X_train, X_test, y_train, y_test = train_test_split(
    images, labels, 
    test_size=0.2, 
    random_state=42,
    stratify=labels  # ØªÙˆØ²ÙŠØ¹ Ù…ØªØ³Ø§ÙˆÙ
)

print(f"Training samples: {len(X_train)}")
print(f"Testing samples: {len(X_test)}")

# 3. Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=20,        # ØªØ¯ÙˆÙŠØ± 20 Ø¯Ø±Ø¬Ø©
    width_shift_range=0.2,    # Ø¥Ø²Ø§Ø­Ø© Ø£ÙÙ‚ÙŠØ©
    height_shift_range=0.2,   # Ø¥Ø²Ø§Ø­Ø© Ø¹Ù…ÙˆØ¯ÙŠØ©
    horizontal_flip=True,     # Ù‚Ù„Ø¨ Ø£ÙÙ‚ÙŠ
    zoom_range=0.2,          # ØªÙ‚Ø±ÙŠØ¨
    brightness_range=[0.8, 1.2]  # ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø·ÙˆØ¹
)

# 4. Normalization (ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ…)
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

print("âœ… Data preparation complete!")
```

---

## 3ï¸âƒ£ **Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Model Architecture)**

### Ø§Ù„Ø®ÙŠØ§Ø± 1: Ù…Ù† Ø§Ù„ØµÙØ± (Custom CNN)

```python
# scripts/train_model.py
import tensorflow as tf
from tensorflow.keras import layers, models

def create_injury_model(num_classes=7):
    """Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN Ù…Ø®ØµØµ"""
    
    model = models.Sequential([
        # Block 1
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 2
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 3
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),
        
        # Block 4
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.5),
        
        # Classification Head
        layers.Flatten(),
        layers.Dense(512, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = create_injury_model()
model.summary()  # Ø¹Ø±Ø¶ Ø§Ù„Ø¨Ù†ÙŠØ©

# Compile
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

### Ø§Ù„Ø®ÙŠØ§Ø± 2: Transfer Learning (Ø£Ø³Ø±Ø¹ ÙˆØ£ÙØ¶Ù„!)

```python
# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±ÙÙ‘Ø¨ Ù…Ø³Ø¨Ù‚Ø§Ù‹
from tensorflow.keras.applications import MobileNetV2

def create_transfer_learning_model(num_classes=7):
    """Ø§Ø³ØªØ®Ø¯Ø§Ù… MobileNetV2 Ù…Ø¹ Fine-tuning"""
    
    # ØªØ­Ù…ÙŠÙ„ MobileNetV2 (Ù…ÙØ¯Ø±ÙÙ‘Ø¨ Ø¹Ù„Ù‰ ImageNet)
    base_model = MobileNetV2(
        input_shape=(224, 224, 3),
        include_top=False,  # Ø¨Ø¯ÙˆÙ† Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØµÙ†ÙŠÙ
        weights='imagenet'   # Ø£ÙˆØ²Ø§Ù† Ù…ÙØ¯Ø±ÙÙ‘Ø¨Ø©
    )
    
    # ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰ (Ù„Ø§ Ù†Ø¹ÙŠØ¯ ØªØ¯Ø±ÙŠØ¨Ù‡Ø§)
    base_model.trainable = False
    
    # Ø¥Ø¶Ø§ÙØ© Ø·Ø¨Ù‚Ø§Øª Ù…Ø®ØµØµØ©
    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = create_transfer_learning_model()

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

---

## 4ï¸âƒ£ **Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Training)**

```python
# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ù„ÙŠ
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# Callbacks Ù„Ù„ØªØ­Ø³ÙŠÙ†
callbacks = [
    # Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¨ÙƒØ± Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ­Ø³Ù†
    EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True
    ),
    
    # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
    ModelCheckpoint(
        'models/best_injury_model.h5',
        monitor='val_accuracy',
        save_best_only=True
    ),
    
    # ØªÙ‚Ù„ÙŠÙ„ learning rate
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5
    )
]

# Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    validation_data=(X_test, y_test),
    epochs=50,  # Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª
    callbacks=callbacks,
    verbose=1
)

print("âœ… Training complete!")

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.save('models/injury_detector_final.h5')
```

### ğŸ“Š Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨:

```python
import matplotlib.pyplot as plt

# Ø±Ø³Ù… Ù…Ù†Ø­Ù†ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
plt.figure(figsize=(12, 4))

# Accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.savefig('training_history.png')
print("âœ… Training plots saved!")
```

---

## 5ï¸âƒ£ **Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (Evaluation)**

```python
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„
classes = ['normal', 'bleeding', 'bruise', 'burn', 'cut', 'fracture', 'swelling']
print(classification_report(y_test, y_pred_classes, target_names=classes))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=classes, yticklabels=classes)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.savefig('confusion_matrix.png')

print("âœ… Evaluation complete!")
```

---

## 6ï¸âƒ£ **Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ TFLite (Ù„Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Edge)**

```python
# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±ÙÙ‘Ø¨ Ù„Ù€ TensorFlow Lite
import tensorflow as tf

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model = tf.keras.models.load_model('models/injury_detector_final.h5')

# Ø¥Ù†Ø´Ø§Ø¡ Converter
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# ØªØ·Ø¨ÙŠÙ‚ Optimizations (ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù…)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# Optional: Quantization (Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ø£ÙƒØ«Ø±)
converter.target_spec.supported_types = [tf.float16]

# Ø§Ù„ØªØ­ÙˆÙŠÙ„
tflite_model = converter.convert()

# Ø­ÙØ¸
output_path = 'backend/ai_engine/models/injury_detector.tflite'
with open(output_path, 'wb') as f:
    f.write(tflite_model)

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
import os
file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
print(f"âœ… TFLite model saved!")
print(f"ğŸ“¦ Size: {file_size:.2f} MB")
```

---

## 7ï¸âƒ£ **Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹**

```python
# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯
from backend.ai_engine.injury_detector import InjuryDetector

# Ø¥Ù†Ø´Ø§Ø¡ detector (Ø³ÙŠØ­Ù…Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
detector = InjuryDetector()

# Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ ØµÙˆØ±Ø©
injuries = detector.detect_from_image('test_images/wound.jpg')

for injury in injuries:
    print(f"Type: {injury['type']}")
    print(f"Confidence: {injury['confidence']:.2%}")
    print(f"Severity: {injury['severity']}")
    print("---")
```

---

## ğŸ“Š **Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©**

### Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ø§Ø¬Ø­:

```
âœ… Accuracy Ø¹Ù„Ù‰ Test Set: 85-95%
âœ… Model Size: 5-15 MB (TFLite)
âœ… Inference Time: 100-200ms per image
âœ… ÙŠØ¹Ù…Ù„ Offline Ø¹Ù„Ù‰ Raspberry Pi
```

### Confusion Matrix Ù…Ø«Ø§Ù„ÙŠØ©:
```
              Precision  Recall  F1-Score
normal           0.95     0.97     0.96
bleeding         0.90     0.88     0.89
bruise           0.87     0.85     0.86
burn             0.92     0.90     0.91
cut              0.88     0.87     0.87
fracture         0.85     0.83     0.84
swelling         0.86     0.84     0.85
```

---

## ğŸš€ **Ø³ÙƒØ±ÙŠØ¨Øª ÙƒØ§Ù…Ù„ Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„**

```python
# scripts/train_injury_detector.py
"""
Ø³ÙƒØ±ÙŠØ¨Øª ÙƒØ§Ù…Ù„ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ´Ù Ø§Ù„Ø¥ØµØ§Ø¨Ø§Øª
"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import cv2

print("ğŸš€ Starting Injury Detection Model Training...")
print(f"TensorFlow version: {tf.__version__}")

# ====================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ====================
print("\nğŸ“Š Loading dataset...")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
def load_images_from_folder(folder, img_size=(224, 224)):
    images = []
    labels = []
    classes = sorted(os.listdir(folder))
    
    for idx, class_name in enumerate(classes):
        class_dir = os.path.join(folder, class_name)
        if not os.path.isdir(class_dir):
            continue
            
        print(f"  Loading {class_name}...")
        count = 0
        
        for img_name in os.listdir(class_dir):
            if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            img_path = os.path.join(class_dir, img_name)
            img = cv2.imread(img_path)
            
            if img is None:
                continue
                
            img = cv2.resize(img, img_size)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            images.append(img)
            labels.append(idx)
            count += 1
        
        print(f"    âœ… Loaded {count} images")
    
    return np.array(images), np.array(labels), classes

images, labels, class_names = load_images_from_folder('dataset/')
print(f"\nâœ… Total images: {len(images)}")
print(f"ğŸ“‹ Classes: {class_names}")

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
X_train, X_test, y_train, y_test = train_test_split(
    images, labels, test_size=0.2, random_state=42, stratify=labels
)

# Normalization
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

print(f"ğŸ“ˆ Training set: {len(X_train)} samples")
print(f"ğŸ“‰ Test set: {len(X_test)} samples")

# ====================
# 2. Data Augmentation
# ====================
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    brightness_range=[0.8, 1.2]
)

# ====================
# 3. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# ====================
print("\nğŸ—ï¸  Building model...")

base_model = MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(len(class_names), activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# ====================
# 4. Ø§Ù„ØªØ¯Ø±ÙŠØ¨
# ====================
print("\nğŸ‹ï¸  Training model...")

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

callbacks = [
    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),
    ModelCheckpoint('models/best_model.h5', monitor='val_accuracy', save_best_only=True)
]

os.makedirs('models', exist_ok=True)

history = model.fit(
    datagen.flow(X_train, y_train, batch_size=32),
    validation_data=(X_test, y_test),
    epochs=30,
    callbacks=callbacks,
    verbose=1
)

# ====================
# 5. Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
# ====================
print("\nğŸ“Š Evaluating model...")

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"âœ… Test Accuracy: {test_acc:.2%}")
print(f"âœ… Test Loss: {test_loss:.4f}")

# ====================
# 6. Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ TFLite
# ====================
print("\nğŸ“¦ Converting to TFLite...")

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

tflite_path = 'backend/ai_engine/models/injury_detector.tflite'
os.makedirs(os.path.dirname(tflite_path), exist_ok=True)

with open(tflite_path, 'wb') as f:
    f.write(tflite_model)

file_size = os.path.getsize(tflite_path) / (1024 * 1024)
print(f"âœ… TFLite model saved: {tflite_path}")
print(f"ğŸ“¦ Size: {file_size:.2f} MB")

# Ø­ÙØ¸ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª
with open('backend/ai_engine/models/class_names.txt', 'w') as f:
    f.write('\n'.join(class_names))

print("\nğŸ‰ Training complete!")
print(f"ğŸ“ˆ Final accuracy: {test_acc:.2%}")
print(f"ğŸ“ Model saved at: {tflite_path}")
```

---

## âš¡ **ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨**

```bash
# 1. Ø«Ø¨Ù‘Øª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
pip install tensorflow opencv-python scikit-learn matplotlib seaborn

# 2. Ø¬Ù‡Ù‘Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ:
#    dataset/bleeding/
#    dataset/bruise/
#    ... Ø¥Ù„Ø®

# 3. Ø´ØºÙ‘Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
python scripts/train_injury_detector.py

# 4. Ø§Ù†ØªØ¸Ø±... (2-6 Ø³Ø§Ø¹Ø§Øª)

# 5. Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø§Ù‡Ø²!
# âœ… backend/ai_engine/models/injury_detector.tflite
```

---

## âœ… **Ø§Ù„Ø®Ù„Ø§ØµØ©**

### Ù…Ø§ ØªØ­ØªØ§Ø¬Ù‡:
```
1. ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª (500+ ØµÙˆØ±Ø© Ù„ÙƒÙ„ ÙØ¦Ø©)
2. ğŸ’» Ø¬Ù‡Ø§Ø² Ù‚ÙˆÙŠ Ø£Ùˆ Google Colab (Ù…Ø¬Ø§Ù†ÙŠ!)
3. â±ï¸ ÙˆÙ‚Øª (6-12 Ø³Ø§Ø¹Ø© Ø¥Ø¬Ù…Ø§Ù„ÙŠ)
4. ğŸ§  ØµØ¨Ø± ÙˆØªØ¬Ø±Ø¨Ø©
```

### Ø§Ù„Ù†ØªÙŠØ¬Ø©:
```
âœ… Ù†Ù…ÙˆØ°Ø¬ AI Ù…Ø®ØµØµ 100%
âœ… Ø¯Ù‚Ø© 85-95%
âœ… ÙŠØ¹Ù…Ù„ Offline
âœ… Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ù€ Raspberry Pi
âœ… Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªØ®Ø±Ø¬
```

---

**Ø¬Ø§Ù‡Ø² Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŸ ğŸš€**
